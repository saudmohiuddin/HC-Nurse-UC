Summary

Use Case

This Flask application is designed for oncology nurses to collect patient data during their shifts, transcribe audio notes using OpenAI’s Whisper model, and store the data in MongoDB Atlas. The nurses can log multiple audio recordings throughout the day. These recordings are transcribed and summarized at the end of the day, allowing nurses to review an organized summary of their interactions and patient details. The app integrates real-time audio-to-text capabilities and captures relevant patient data, including health status, medications, and daily fluid intake/output.

Technology Stack

	•	Flask (Python): The backend framework used to create the web application.
	•	JavaScript (with jQuery): Handles the client-side logic for data collection, audio recording, and interaction with the Flask API.
	•	MongoDB Atlas: Stores patient data, transcriptions, and summaries. Create a database on MongoDB Atlas to define collections based on the Models file.
	•	OpenAI Whisper: Used for audio transcription. Please download the smallest model (~483mb) from Hugginface or another source.
	•	LLM (Language Model): Generates end-of-day summaries of transcriptions. Llama3.1 is used locally with Ollama. Please install Ollama on your local machine for transcription summarization.
	•	HTML/CSS/Bootstrap: For the frontend design of the web app.

File Descriptions

	1.	models.py - Defines the data models and schema for the application, including patient information and nurse details. Connects with MongoDB.
	2.	routes.py - Handles all the Flask routes, including serving the web pages, processing form submissions, and managing API calls.
	3.	whisper_app.py - Integrates OpenAI Whisper to transcribe audio into text.
	4.	ollama_api_server.py - Handles interaction with the LLM for generating summaries based on transcribed audio.
	5.	run.py - The entry point for running the Flask application.
	6.	index.html - The main page of the web application where nurses can input patient data, select a patient, and interact with the recording features.
	7.	main.js - Manages patient and nurse data retrieval, form submissions, and event listeners on the frontend.
	8.	recording.js - Manages the frontend recording functionality, including starting/stopping audio recordings and interacting with the server to upload audio files.
	9.	recorder.js - Handles audio recording on the frontend, including managing microphone permissions, waveform display, and sending the recorded audio to the backend.

 File: models.py

Overview:

The models.py file is responsible for defining the structure of the data stored in MongoDB. This file typically contains schema definitions that outline what kind of data is captured in the application. For this project, the focus is on the patients, nurses, audio recordings, and summaries, which are essential components of the web app. These schemas provide the blueprint for how MongoDB stores and retrieves structured data.

Key Components:

	1.	MongoDB Connection:
This connection allows the application to store patient details, nurse data, transcriptions, and audio summaries.

  2.	Patient Model:
The Patient model defines the structure for storing patient data. It includes fields like the patient’s name, date of birth, medical history, and a unique identifier (e.g., medical record number or patient ID). This schema ensures that every patient entry is consistent and retrievable by the application.
Fields in the Patient Model:
	•	name: The patient’s full name.
	•	dob: The patient’s date of birth.
	•	medical_history: A brief description of the patient’s medical history.
	•	mrn: Medical Record Number or another unique identifier for the patient.
	•	recordings: A list of references or IDs pointing to audio recordings linked to this patient.
Usage in the app: The nurse selects or enters patient information in the frontend, which the application stores in this schema for later retrieval and use during audio transcriptions and data summaries.

  3.	Nurse Model:
The Nurse model defines the schema for nurses who use the app. Nurses are responsible for recording patient notes and filling out forms, and the schema captures basic identifying information.
Fields in the Nurse Model:
	•	first_name: The nurse’s first name.
	•	last_name: The nurse’s last name.
	•	nurse_id: A unique identifier for the nurse (auto-generated).

  4.	Recording Model:
The Recording model handles the structure for audio files recorded by nurses during their shifts. This model stores important details, including the transcription generated by OpenAI Whisper, metadata about the recording, and the actual audio file (or a reference to its location).
Fields in the Recording Model:
	•	patient_id: Links this recording to a specific patient.
	•	nurse_id: Identifies the nurse who made the recording.
	•	timestamp: The time when the recording was created.
	•	audio_url: A reference to the location of the stored audio file.
	•	transcription: The text generated from the audio using Whisper.

  5.	Summary Model:
The Summary model is responsible for capturing the end-of-day summaries generated by the LLM based on multiple transcriptions throughout the day. This model helps ensure that a coherent summary is available for each patient by the end of the nurse’s shift.
Fields in the Summary Model:
	•	patient_id: Links the summary to the specific patient.
	•	nurse_id: Identifies the nurse who created the recordings.
	•	summary_text: The generated summary based on the transcriptions.
	•	date: The date when the summary was generated.

Relation to Other Files:

	•	routes.py: Interacts with the models to handle HTTP requests for creating, reading, updating, and deleting patient, nurse, and recording data. The routes.py file uses the schemas defined in models.py to retrieve and store data in MongoDB.
	•	whisper_app.py and ollama_api_server.py: These files reference the Recording and Summary models for storing and retrieving transcriptions and LLM-generated summaries.

File: routes.py

Overview:

The routes.py file defines the different endpoints (routes) that the Flask application exposes. These routes handle various actions such as loading the web pages, receiving form data, processing audio uploads, and generating summaries. Each route corresponds to a specific function or API call and processes data either sent from the frontend or fetched from the database.

Key Components:

	1.	Route Definitions:
Each route in Flask is defined using the @app.route() decorator, which binds a URL to a specific function. These routes allow interaction between the frontend and backend, handling tasks like rendering templates, receiving data submissions, and returning JSON responses.
	
 2.	Home Page Route (GET):
The home page is typically served using a GET request, rendering the main HTML page (likely index.html). This page contains the form for selecting a nurse and patient, as well as the UI elements for recording and transcribing audio.
Relation to the app: This route renders the primary UI where nurses interact with the app. It sends the HTML template (index.html) to the client, which includes the form and audio recording controls.

	3.	Fetching Nurses and Patients (GET):
Two routes are responsible for retrieving available nurses and patients from the database, which are then populated in the dropdowns on the UI.
Relation to the app: These routes populate the nurse and patient selection fields on the front-end form (index.html). When the user opens the page, these routes are triggered to ensure the nurse and patient options are up-to-date.

  4.	Adding New Nurse and Patient (POST):
These routes handle form submissions when a new nurse or patient is added. When a nurse enters new data in the front-end form, the app sends a POST request with the new data, which the backend then stores in MongoDB.
Relation to the app: These routes allow the system to expand dynamically by adding new patients and nurses without requiring manual database updates.

  5.	Audio Upload and Transcription (POST):
This route is critical for handling audio recordings uploaded from the frontend. Once a nurse records audio, the file is sent to the backend via a POST request, which stores the file in the database and triggers the transcription process using OpenAI Whisper.
Relation to the app: This route accepts audio recordings, stores them in MongoDB, and runs the Whisper transcription model to convert the audio into text, which is returned as a response to the frontend.

  6.	Fetching Recordings (GET):
This route retrieves the recordings and their associated transcriptions for a specific patient and nurse combination. This allows nurses to view all audio logs and transcriptions for a particular patient, recorded by the selected nurse during a shift.
Relation to the app: This route retrieves previously recorded and transcribed audio files, allowing nurses to view or listen to the recorded sessions.

  7.	Generating Summary (POST):
This route generates an end-of-day summary for a specific patient by processing all transcriptions collected during the day. The data is sent to an LLM (via ollama_api_server.py), which generates a summarized report.
Relation to the app: This route consolidates multiple recordings into a single, easy-to-read summary for end-of-day reporting. Nurses can review these summaries to ensure all patient interactions are captured and accurate.

  8.	Fetching Latest Summary (GET):
This route retrieves the most recent summary for a given patient and nurse. It is used to display the summary on the UI after it’s generated.
Relation to the app: This route ensures that the nurse can view the most up-to-date summary after their shift, facilitating seamless reporting.

Relation to Other Files:

	•	models.py: This file directly interacts with the models defined in models.py, using them to store and retrieve patient, nurse, audio, and summary data from MongoDB.
	•	index.html and JavaScript files (main.js, recording.js): These frontend files interact with the routes in routes.py through GET and POST requests, sending and receiving data from the server to update the UI and process data submissions.
